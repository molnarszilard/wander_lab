Using wander lab with jetbot

Welcome to the 2nd Laboratory of EFAC.
This repository is a supplimentary material for this lab: https://sites.google.com/view/utcn-efac/labs/lab2

Here you can find the scripts for the solution of this lab.
For the main part of the lab, you need to use the simulator as it is described in the documentation.

The addition of the repo is that you can try out the code in real life using a Jetbot with a Jetson Nano.


Then to check if you can control the robot, run

 - rosrun teleop_twist_keyboard teleop_twist_keyboard.py /cmd_vel:=/RosAria/cmd_vel

and move around.

Go to catkin_ws, catkin_make, source devel/setup.bash
 - roslaunch wander_lab pioneer_start_pico.launch

 - rosrun wander_lab p3_wander_pico

 (if you don't have the package for the pico zense, then clone it from: https://github.com/molnarszilard/pico_zense_camera)
 (if you are running it on jetson, inside the pico_zense_camera/src/pico_zense_camera/lib/ overwrite the files with the files from the zip there)
 (the depthimage_to_laserscan wont work from git on jetson, install it by apt. Then WITHOUT source devel/setup.bash, roslaunch depth_laser_scan.launch from the launch folder)
_______
Additional information:

_______
Installation
(make sure that python and ros are installed)


sudo apt update
pip3 install sparkfun-qwiic-scmd
pip3 install traitlets

mkdir catkin_ws/src
cd catkin_ws/src/
git clone https://github.com/molnarszilard/pico_zense_camera.git
cd pico_zense_camera/src/pico_zense_camera/lib
unzip pico_lib_jetson.zip
mv lib/* ./
cd ../../../../../


sudo nano /opt/ros/melodic/share/cv_bridge/cmake/cv_bridgeConfig.cmake
 - change according to: https://github.com/ros-perception/vision_opencv/issues/345#issuecomment-663416626

     set(_include_dirs "include;/usr/include;/usr/include/opencv")
           to
     set(_include_dirs "include;/usr/include;/usr/include/opencv4")
sudo apt-get install ros-melodic-depthimage-to-laserscan
catkin_make
